Цель этого домашнего задания проста, но фактическая реализация может 
занять некоторое время :). Мы собираемся написать Искусственную 
Нейронную Сеть (почти) с нуля. Разработка программного обеспечения 
была в значительной степени вдохновлена ??Torch, который является 
наиболее удобной средой нейронной сети, когда работа связана с 
определением новых уровней.

Это домашнее задание требует отправки нескольких файлов, пожалуйста, 
не забудьте включить все файлы при отправке в TA. Список файлов:

Этот блокнот
homework_modules.ipynb
homework_differentiation.ipynb

Реализуйте все в Modules.ipynb. Прочитайте все комментарии вдумчиво, 
чтобы облегчить боль. Пожалуйста, постарайтесь не менять прототипы.

Не забывайте, что каждый модуль должен возвращать И хранить выходные 
данные и gradInput.

Типичным предположением является то, что module.backward всегда 
выполняется после module.forward, поэтому выходные данные сохраняются,
 это было бы полезно для SoftMax.

Техническая записка
Предпочитайте использовать np.multiply, np.add, np.divide, 
np.subtract вместо *, +, /, - для лучшей обработки памяти.

Пример: предположим, что вы выделили переменную

a = np.zeros (...)
Итак, вместо

a = b + c # будет перераспределен, GC необходимо освободить
Ты можешь использовать:

np.add (b, c, out = a) # помещает результат в `a`